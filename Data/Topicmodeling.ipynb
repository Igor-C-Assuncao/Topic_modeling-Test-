{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>ISD</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Links</th>\n",
       "      <th>Publication Type</th>\n",
       "      <th>Search Engine</th>\n",
       "      <th>VALIDAÇÃO</th>\n",
       "      <th>PDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1535</td>\n",
       "      <td>Reconstructing Missing EHRs Using Time-Aware W...</td>\n",
       "      <td>Real-world Electronic Health Records (EHRs) ar...</td>\n",
       "      <td>Electronic Health Records(EHRs), EHRs Imputati...</td>\n",
       "      <td>G. Gao; F. Khoshnevisan; M. Chi</td>\n",
       "      <td>2022</td>\n",
       "      <td>2575-2634</td>\n",
       "      <td>10.1109/ICHI54592.2022.00034</td>\n",
       "      <td>https://ieeexplore.ieee.org/stamp/stamp.jsp?ar...</td>\n",
       "      <td>IEEE Conferences</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>AC</td>\n",
       "      <td>2203.08245v2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>3D-MICE: integration of cross-sectional and lo...</td>\n",
       "      <td>A key challenge in clinical data mining is tha...</td>\n",
       "      <td>machine learning, imputation, missing data, el...</td>\n",
       "      <td>Baron JM</td>\n",
       "      <td>2018</td>\n",
       "      <td>1527-974X</td>\n",
       "      <td>10.1093/jamia/ocx133</td>\n",
       "      <td>https://pubmed.ncbi.nlm.nih.gov/29202205/</td>\n",
       "      <td>Journal Article Research Support, Non-U.S. Gov't</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>AC</td>\n",
       "      <td>3D-MICE.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1385</td>\n",
       "      <td>Performance evaluation of a recurrent deep neu...</td>\n",
       "      <td>Atmospheric pollution refers to the presence o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pedraza-Ortega JC</td>\n",
       "      <td>2022</td>\n",
       "      <td>2162-2906</td>\n",
       "      <td>10.1080/10962247.2022.2095057</td>\n",
       "      <td>https://pubmed.ncbi.nlm.nih.gov/35816429/</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>AC</td>\n",
       "      <td>Performance evaluation of a recurrent deep neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433</td>\n",
       "      <td>Predicting progression of Alzheimer's disease ...</td>\n",
       "      <td>If left untreated, Alzheimer's disease (AD) is...</td>\n",
       "      <td>Alzheimer’s progression, MRI biomarker forecas...</td>\n",
       "      <td>Pant S</td>\n",
       "      <td>2022</td>\n",
       "      <td>1879-2782</td>\n",
       "      <td>S0893-6080(22)00094-6</td>\n",
       "      <td>https://pubmed.ncbi.nlm.nih.gov/35364417/</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>AC</td>\n",
       "      <td>1-s2.0-S0893608022000946-main.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369</td>\n",
       "      <td>Causes and Consequences of Missing Health-Rela...</td>\n",
       "      <td>Missing health-related quality of life (HRQOL)...</td>\n",
       "      <td>longitudinal studies , quality of life , regis...</td>\n",
       "      <td>Spertus JA</td>\n",
       "      <td>2017</td>\n",
       "      <td>1941-7705</td>\n",
       "      <td>10.1161/CIRCOUTCOMES.116.003268</td>\n",
       "      <td>https://pubmed.ncbi.nlm.nih.gov/29246883/</td>\n",
       "      <td>Comparative Study Journal Article Multicenter ...</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>AC</td>\n",
       "      <td>grady2017.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                              Title  \\\n",
       "0  1535  Reconstructing Missing EHRs Using Time-Aware W...   \n",
       "1    16  3D-MICE: integration of cross-sectional and lo...   \n",
       "2  1385  Performance evaluation of a recurrent deep neu...   \n",
       "3  1433  Predicting progression of Alzheimer's disease ...   \n",
       "4   369  Causes and Consequences of Missing Health-Rela...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Real-world Electronic Health Records (EHRs) ar...   \n",
       "1  A key challenge in clinical data mining is tha...   \n",
       "2  Atmospheric pollution refers to the presence o...   \n",
       "3  If left untreated, Alzheimer's disease (AD) is...   \n",
       "4  Missing health-related quality of life (HRQOL)...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  Electronic Health Records(EHRs), EHRs Imputati...   \n",
       "1  machine learning, imputation, missing data, el...   \n",
       "2                                                NaN   \n",
       "3  Alzheimer’s progression, MRI biomarker forecas...   \n",
       "4  longitudinal studies , quality of life , regis...   \n",
       "\n",
       "                           Authors  Year        ISD  \\\n",
       "0  G. Gao; F. Khoshnevisan; M. Chi  2022  2575-2634   \n",
       "1                         Baron JM  2018  1527-974X   \n",
       "2                Pedraza-Ortega JC  2022  2162-2906   \n",
       "3                           Pant S  2022  1879-2782   \n",
       "4                       Spertus JA  2017  1941-7705   \n",
       "\n",
       "                               DOI  \\\n",
       "0     10.1109/ICHI54592.2022.00034   \n",
       "1             10.1093/jamia/ocx133   \n",
       "2    10.1080/10962247.2022.2095057   \n",
       "3            S0893-6080(22)00094-6   \n",
       "4  10.1161/CIRCOUTCOMES.116.003268   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://ieeexplore.ieee.org/stamp/stamp.jsp?ar...   \n",
       "1          https://pubmed.ncbi.nlm.nih.gov/29202205/   \n",
       "2          https://pubmed.ncbi.nlm.nih.gov/35816429/   \n",
       "3          https://pubmed.ncbi.nlm.nih.gov/35364417/   \n",
       "4          https://pubmed.ncbi.nlm.nih.gov/29246883/   \n",
       "\n",
       "                                    Publication Type Search Engine VALIDAÇÃO  \\\n",
       "0                                   IEEE Conferences          IEEE        AC   \n",
       "1   Journal Article Research Support, Non-U.S. Gov't        PubMed        AC   \n",
       "2                                    Journal Article        PubMed        AC   \n",
       "3                                    Journal Article        PubMed        AC   \n",
       "4  Comparative Study Journal Article Multicenter ...        PubMed        AC   \n",
       "\n",
       "                                                 PDF  \n",
       "0                                   2203.08245v2.pdf  \n",
       "1                                        3D-MICE.pdf  \n",
       "2  Performance evaluation of a recurrent deep neu...  \n",
       "3                  1-s2.0-S0893608022000946-main.pdf  \n",
       "4                                      grady2017.pdf  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(module_path, 'Data', 'artigos.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df = pd.read_csv(data_path, delimiter=',')\n",
    "df.columns = [col.strip().replace('\"', '') for col in df.columns]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = df[['ID', 'Abstract']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1535,\n",
       "       'Real-world Electronic Health Records (EHRs) are often plagued by a high rate of missing data. In our EHRs, for example, the missing rates can be as high as 90% for some features, with an average missing rate of around 70% across all features. We propose a Time-Aware Dual-Cross-Visit missing value imputation method, named TA-DualCV, which spontaneously leverages multivariate dependencies across features and longitudinal dependencies both within- and cross-visit to maximize the information extracted from limited observable records in EHRs. Specifically, TA-DualCV captures the latent structure of missing patterns across measurements of different features and it also considers the time continuity and capture the latent temporal missing patterns based on both time-steps and irregular time-intervals. TA-DualCV is evaluated using three large real-world EHRs on two types of tasks: an unsupervised imputation task by varying mask rates up to 90% and a supervised 24-hour early prediction of septic shock using Long Short-Term Memory (LSTM). Our results show that TA-DualCV performs significantly better than all of the existing state-of-the-art imputation baselines, such as DETROIT and TAME, on both types of tasks.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    realworld electronic health records ehrs often...\n",
      "1    key challenge clinical data mining clinical da...\n",
      "2    atmospheric pollution refers presence substanc...\n",
      "3    left untreated alzheimers disease ad leading c...\n",
      "4    missing healthrelated quality life hrqol data ...\n",
      "Name: cleaned_abstract, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\igorc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Baixar stopwords em português\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Palavras adicionais a serem removidas\n",
    "custom_stopwords = [\n",
    "    \"time series\", \"temporal\", \"reconstruct\", \n",
    "    \"missing values\", \"missing data\", \"incomplete data\"\n",
    "]\n",
    "\n",
    "# Regex para capturar palavras que começam com \"multi\" (case insensitive)\n",
    "multi_regex = re.compile(r'\\bmulti\\w*', flags=re.IGNORECASE)\n",
    "imput_regex = re.compile(r'\\bimput\\w*', flags=re.IGNORECASE)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Converter para minúsculas\n",
    "    text = text.lower()\n",
    "    # Remover pontuação\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remover palavras compostas específicas\n",
    "    for phrase in custom_stopwords:\n",
    "        text = text.replace(phrase, \"\")\n",
    "    # Remover palavras que começam com \"multi\"\n",
    "    text = re.sub(multi_regex, '', text)\n",
    "    text = re.sub(imput_regex, '', text)\n",
    "    # Remover stopwords simples\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Aplicar ao DataFrame (considerando que temos a coluna 'Abstract')\n",
    "df['cleaned_abstract'] = df['Abstract'].apply(preprocess_text)\n",
    "\n",
    "# Ver abstracts limpos\n",
    "print(df['cleaned_abstract'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0007' '001' '00130015' ... 'york' 'zealand' 'zone']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "dtm = vectorizer.fit_transform(df['cleaned_abstract'])  # Document-Term Matrix\n",
    "\n",
    "\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico 1:\n",
      "['mean', 'patients', 'prediction', 'septic', 'longitudinal', 'scores', 'shock', 'data', 'hrqol', 'missing']\n",
      "Tópico 2:\n",
      "['analysis', 'dependencies', 'propose', 'model', 'time', 'graph', 'ta', 'method', 'missing', 'data']\n",
      "Tópico 3:\n",
      "['professionalization', 'mice', 'missing', '3dmice', 'nurse', 'data', 'gender', 'results', 'nursing', 'clinical']\n",
      "Tópico 4:\n",
      "['knowledge', 'one', 'however', 'often', 'learning', 'challenge', 'architecture', 'model', 'clinical', 'data']\n",
      "Tópico 5:\n",
      "['neural', 'results', 'aod', 'methodology', 'model', 'deep', 'modeling', 'using', 'network', 'data']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "K = 5 \n",
    "\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=K, random_state=42)\n",
    "lda_model.fit(dtm)\n",
    "\n",
    "\n",
    "for index, topic in enumerate(lda_model.components_):\n",
    "    print(f\"Tópico {index + 1}:\")\n",
    "    print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tópico 1</th>\n",
       "      <th>Tópico 2</th>\n",
       "      <th>Tópico 3</th>\n",
       "      <th>Tópico 4</th>\n",
       "      <th>Tópico 5</th>\n",
       "      <th>Documento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.992729</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>1535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.994786</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.996423</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994646</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995163</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.991514</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.993225</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.994805</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.989413</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.996315</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.989665</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.994210</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.995578</td>\n",
       "      <td>1723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.994295</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>1785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.989891</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.993707</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tópico 1  Tópico 2  Tópico 3  Tópico 4  Tópico 5  Documento\n",
       "0   0.001831  0.992729  0.001812  0.001811  0.001817       1535\n",
       "1   0.001303  0.001304  0.994786  0.001306  0.001301         16\n",
       "2   0.000894  0.000895  0.000894  0.000894  0.996423       1385\n",
       "3   0.994646  0.001347  0.001332  0.001335  0.001339       1433\n",
       "4   0.995163  0.001210  0.001210  0.001207  0.001211        369\n",
       "5   0.002121  0.991514  0.002115  0.002121  0.002129        375\n",
       "6   0.001414  0.166300  0.001409  0.001419  0.829457        447\n",
       "7   0.993225  0.001693  0.001693  0.001694  0.001696       1656\n",
       "8   0.001297  0.001297  0.001303  0.994805  0.001297        718\n",
       "9   0.002642  0.989413  0.002642  0.002652  0.002651       1282\n",
       "10  0.000921  0.000922  0.996315  0.000921  0.000921        816\n",
       "11  0.002591  0.989665  0.002585  0.002577  0.002583        855\n",
       "12  0.001447  0.994210  0.001443  0.001449  0.001451        935\n",
       "13  0.001106  0.001107  0.001103  0.001105  0.995578       1723\n",
       "14  0.001424  0.994295  0.001423  0.001431  0.001426       1785\n",
       "15  0.002524  0.002544  0.002521  0.989891  0.002521       1228\n",
       "16  0.001571  0.001576  0.001568  0.993707  0.001578       2009"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribuição de tópicos por documento\n",
    "doc_topic_dist = lda_model.transform(dtm)\n",
    "\n",
    "\n",
    "topic_df = pd.DataFrame(doc_topic_dist, columns=[f\"Tópico {i+1}\" for i in range(K)])\n",
    "topic_df['Documento'] = df['ID']  # Adicionar identificação do documento\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "topic_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df.to_csv('topicos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "c:\\Python312\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "c:\\Python312\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "c:\\Python312\\Lib\\site-packages\\joblib\\_utils.py:39: DeprecationWarning: Attribute n is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return node.n\n",
      "c:\\Python312\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "c:\\Python312\\Lib\\site-packages\\joblib\\_utils.py:39: DeprecationWarning: Attribute n is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return node.n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2600026305195889441095926805\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2600026305195889441095926805_data = {\"mdsDat\": {\"x\": [-0.13418312685304054, -0.01840032795074026, 0.01602486264455917, 0.12058547755322377, 0.015973114605997873], \"y\": [-0.07235118657545182, 0.12286808627739128, 0.06490944482452281, -0.06351010420598915, -0.05191624032047313], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [27.924678960813164, 22.344522886350973, 18.481770613897467, 15.880139083080874, 15.368888455857526]}, \"tinfo\": {\"Term\": [\"clinical\", \"nursing\", \"hrqol\", \"gender\", \"scores\", \"ta\", \"nurse\", \"3dmice\", \"shock\", \"graph\", \"mean\", \"septic\", \"deep\", \"method\", \"methodology\", \"aod\", \"patients\", \"longitudinal\", \"modeling\", \"measurements\", \"prediction\", \"learning\", \"regimes\", \"professionalization\", \"network\", \"results\", \"architecture\", \"dependencies\", \"time\", \"mice\", \"ta\", \"graph\", \"dependencies\", \"ehrs\", \"patterns\", \"decomposition\", \"tadualcv\", \"applied\", \"longterm\", \"two\", \"framework\", \"representation\", \"baselines\", \"structure\", \"capture\", \"evaluated\", \"dependency\", \"fixed\", \"mtsit\", \"transformer\", \"short\", \"method\", \"activity\", \"dictionaries\", \"interpolation\", \"signal\", \"signals\", \"social\", \"tgsd\", \"individuals\", \"time\", \"propose\", \"realworld\", \"stateoftheart\", \"long\", \"correlation\", \"analysis\", \"across\", \"data\", \"missing\", \"model\", \"observations\", \"based\", \"features\", \"high\", \"methods\", \"performance\", \"proposed\", \"using\", \"network\", \"methodology\", \"aod\", \"optimization\", \"maiac\", \"deep\", \"stage\", \"air\", \"rsup2sup\", \"predictions\", \"ehr\", \"acquired\", \"ant\", \"characteristics\", \"colony\", \"contribution\", \"current\", \"dealing\", \"deals\", \"improve\", \"matter\", \"particulate\", \"pm10\", \"pm25\", \"preprocessing\", \"proposes\", \"shows\", \"atmospheric\", \"geographic\", \"nonlinear\", \"spatio\", \"modeling\", \"rmse\", \"neural\", \"network\", \"recurrent\", \"significant\", \"health\", \"using\", \"applications\", \"residual\", \"values\", \"learning\", \"show\", \"presented\", \"model\", \"data\", \"approach\", \"results\", \"performance\", \"prediction\", \"missing\", \"lstm\", \"mean\", \"hrqol\", \"scores\", \"intermacs\", \"mnar\", \"sensitivity\", \"progressive\", \"icu\", \"assessments\", \"months\", \"preimplantation\", \"alzheimers\", \"disease\", \"progression\", \"shock\", \"septic\", \"circulatory\", \"illness\", \"median\", \"profile\", \"random\", \"randomimputed\", \"severity\", \"ad\", \"biomarkers\", \"mri\", \"phenotypic\", \"relations\", \"status\", \"leading\", \"therefore\", \"measurements\", \"patients\", \"mean\", \"longitudinal\", \"factors\", \"critical\", \"analyses\", \"missingness\", \"prediction\", \"missing\", \"associated\", \"patient\", \"predicting\", \"including\", \"data\", \"clinical\", \"using\", \"problem\", \"proposed\", \"nursing\", \"gender\", \"nurse\", \"3dmice\", \"professionalization\", \"regimes\", \"countries\", \"equality\", \"graduate\", \"indicators\", \"policies\", \"policy\", \"ratios\", \"regulated\", \"analytes\", \"gp\", \"masked\", \"determinants\", \"development\", \"earnercarer\", \"macrolevel\", \"united\", \"workforce\", \"chained\", \"contain\", \"equations\", \"mice\", \"13\", \"commonly\", \"given\", \"clinical\", \"results\", \"laboratory\", \"test\", \"data\", \"datasets\", \"missing\", \"analysis\", \"used\", \"autoencoders\", \"layer\", \"relationships\", \"represent\", \"probabilistic\", \"mmf\", \"dacmi\", \"ground\", \"truth\", \"ability\", \"gate\", \"gates\", \"glae\", \"simultaneously\", \"variables\", \"weight\", \"approximate\", \"feature\", \"knowledge\", \"12\", \"academia\", \"achieve\", \"admission\", \"advancing\", \"art\", \"attracted\", \"betterpersonalized\", \"blood\", \"collectively\", \"combine\", \"architecture\", \"dataset\", \"single\", \"result\", \"complexity\", \"demonstrate\", \"synthetic\", \"collected\", \"challenge\", \"clinical\", \"learning\", \"one\", \"matrix\", \"data\", \"often\", \"model\", \"however\", \"network\", \"real\", \"models\", \"available\", \"algorithm\", \"evaluate\", \"machine\"], \"Freq\": [15.0, 6.0, 7.0, 5.0, 5.0, 7.0, 4.0, 4.0, 5.0, 6.0, 6.0, 5.0, 6.0, 9.0, 4.0, 4.0, 5.0, 7.0, 7.0, 4.0, 8.0, 6.0, 3.0, 3.0, 13.0, 13.0, 4.0, 5.0, 8.0, 3.0, 6.79105287319158, 6.0528948749405815, 4.576578564257052, 4.542305714283648, 3.8384207342693797, 3.100262812140507, 3.1002625697674295, 3.1002624627868847, 3.092755900020042, 3.092754503358656, 2.3621047833341295, 2.362104773935914, 2.362104700513042, 2.362104700513042, 2.3621045533022462, 2.362104450692555, 2.3621043557986403, 2.3621043105227373, 2.3621040479678066, 2.3621040479678066, 2.3505100584851366, 7.527152466576518, 1.6239467327913535, 1.6239467327913535, 1.6239467327913535, 1.6239467327913535, 1.6239467327913535, 1.6239467327913535, 1.6239467327913535, 1.6239467179848552, 6.045896062271162, 4.57691710671716, 3.1003915031956617, 3.092836000268132, 3.1003204557142694, 3.1003125636671163, 4.576539715817047, 3.100324376980539, 16.247319558075795, 7.971405990446774, 5.994163337255831, 3.0927564334974944, 3.100368636966734, 3.100307093542796, 3.100334426502304, 3.344518053035299, 3.351388655721012, 3.3446033993012536, 3.2616858506679347, 3.1942242825566844, 4.31848105732145, 4.318480965401337, 2.9254225167380326, 2.92542242249679, 5.015190203317822, 2.228893241347632, 2.228893209144519, 2.2288931447382296, 2.2282153659528703, 2.2282153659311064, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363955436382, 1.532363904701727, 1.532363904701727, 1.532363904701727, 1.532363904701727, 5.015600408837477, 2.9255607521118265, 3.6221386472648938, 7.01629632364022, 2.9251404004790884, 2.2289565922708503, 2.9013112243668395, 6.2561078061958915, 2.2290503773734254, 2.2289932935942423, 2.107574215398294, 2.9254833539288176, 2.8432638548822746, 2.2291353283309157, 4.37431739290421, 7.236520688872109, 2.22890076235277, 3.62235400212768, 2.6885683357870733, 2.650779505624, 3.204633949006531, 2.229034244136691, 2.228807879443016, 6.675671041289971, 4.712238256355627, 2.7488054632009757, 2.7488054632009757, 2.7488054632009757, 2.7488054191605142, 2.7488052786368278, 2.09432785922732, 2.09432785922732, 2.09432785922732, 2.0943277990311215, 2.0943277990311215, 2.0943277990311215, 4.712615385924351, 4.058078310747197, 1.439850243929535, 1.439850243929535, 1.439850243929535, 1.439850243929535, 1.439850243929535, 1.439850243929535, 1.439850243929535, 1.4398501807051487, 1.4398501807051487, 1.4398501807051487, 1.4398501807051487, 1.4398501807051487, 1.4398501807051487, 1.439850112957446, 1.439850112957446, 3.403543204390653, 4.057974111406763, 4.057840971543982, 4.058169072477382, 2.7491470093709105, 2.094394778426313, 2.74901426857195, 2.0943908489685117, 4.058048345774683, 7.33129095210181, 2.7490762454256163, 2.094480051292292, 2.0944836575638273, 2.0944579530161245, 5.366495090421966, 3.4029563346726417, 2.748959478297673, 2.0945187993670964, 2.0944331480292178, 6.328449709964365, 5.087577164679395, 3.8467046180533906, 3.846704496902648, 2.605832068011024, 2.605832068011024, 1.9853957894921919, 1.9853957894921919, 1.9853957894921919, 1.9853957894921919, 1.9853957894921919, 1.9853957894921919, 1.9853957894921919, 1.9853957894921919, 1.985395662160972, 1.985395662160972, 1.985395662160972, 1.3649595037561726, 1.3649595037561726, 1.3649595037561726, 1.3649595037561726, 1.3649595037561726, 1.3649595037561726, 1.3649593700195326, 1.3649593700195326, 1.3649593700195326, 2.605918711750055, 1.9854539509416151, 1.9854539509416151, 1.98547109675392, 6.328665819450646, 5.088616402443792, 1.9854202056425299, 1.985520368654527, 4.467057282605972, 1.9857630807279796, 3.2265196449591973, 1.985577463470147, 1.985485538819939, 1.9573655159418994, 1.9573655159418994, 1.9573655159418994, 1.9573654430332994, 1.9573653429183198, 1.9573652155967751, 1.345688708625908, 1.345688708625908, 1.345688708625908, 1.345688622901676, 1.345688622901676, 1.345688622901676, 1.345688622901676, 1.345688622901676, 1.345688622901676, 1.345688622901676, 1.3456884651748968, 1.9574236121681792, 1.9574808012430884, 0.7340117782011244, 0.7340117782011244, 0.7340117782011244, 0.7340117782011244, 0.7340117782011244, 0.7340117782011244, 0.7340117782011244, 0.7340117782011244, 0.7340117782011244, 0.7340117782011244, 0.7340117782011244, 2.569603477269896, 1.9574131467060885, 1.3457543408993566, 1.3457264150135682, 1.3457560203271222, 1.3457491075863302, 1.3457491075863302, 1.3457442071784345, 2.5694643429229442, 5.015842755367943, 2.5691451466520614, 1.9576372028491265, 1.95740108085726, 7.462731947785042, 1.9577227401938289, 3.1809625756835116, 1.9577187462880667, 1.9572801067500596, 1.3458374443439867, 1.3458339199893525, 1.345809130786645, 1.3457905883178753, 1.345774495362704, 1.3457486904387095], \"Total\": [15.0, 6.0, 7.0, 5.0, 5.0, 7.0, 4.0, 4.0, 5.0, 6.0, 6.0, 5.0, 6.0, 9.0, 4.0, 4.0, 5.0, 7.0, 7.0, 4.0, 8.0, 6.0, 3.0, 3.0, 13.0, 13.0, 4.0, 5.0, 8.0, 3.0, 7.307677571403524, 6.569519564189703, 5.093203510379601, 5.0912705883315805, 4.35504552501401, 3.616887527682197, 3.616887496931558, 3.61688748274911, 3.616464095872366, 3.6164640056824218, 2.878729516857293, 2.8787295158873283, 2.8787295063495195, 2.8787295063495195, 2.8787294876508596, 2.878729474208389, 2.8787294622162034, 2.8787294559259324, 2.8787294218885533, 2.8787294218885533, 2.878075513795485, 9.320663320633551, 2.140571503216273, 2.140571503216273, 2.140571503216273, 2.140571503216273, 2.140571503216273, 2.140571503216273, 2.140571503216273, 2.1405715016881346, 8.446968847589396, 6.359410086998203, 4.228586509160118, 4.228154790163718, 4.271371639323803, 4.313419520446222, 7.6510171200554735, 4.849011115578751, 40.780124567760886, 22.46660221315835, 15.0787002740359, 4.891376821263833, 4.967903364364328, 5.537528222812481, 5.621637920048236, 7.573542433886266, 8.260968357752818, 8.210517163220711, 14.365266969831543, 13.731492717274051, 4.843431167304522, 4.843431161111227, 3.4503726358486575, 3.4503726294989736, 6.194448880778718, 2.753843369770746, 2.7538433676009992, 2.7538433632615025, 2.7538838337348093, 2.7538838337361096, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573141029706674, 2.0573140995523227, 2.0573140995523227, 2.0573140995523227, 2.0573140995523227, 7.587047807361784, 4.188522253607625, 5.623206615007284, 13.731492717274051, 4.759349944489178, 3.3655279967839156, 4.8104092214795795, 14.365266969831543, 3.491991799305296, 3.4919952649167265, 3.499251893982688, 6.517521619668166, 6.324253324239353, 4.103662647667266, 15.0787002740359, 40.780124567760886, 4.640470139385553, 13.899912160881158, 8.260968357752818, 8.86993162664965, 22.46660221315835, 5.622798038032923, 6.68070377104275, 7.209031536068151, 5.245598756464444, 3.282165976908094, 3.282165976908094, 3.282165976908094, 3.2821659775800383, 3.282165977816723, 2.6276883837586795, 2.6276883837586795, 2.6276883837586795, 2.627688384677118, 2.627688384677118, 2.627688384677118, 5.9837083944297955, 5.329238402827733, 1.9732107906745, 1.9732107906745, 1.9732107906745, 1.9732107906745, 1.9732107906745, 1.9732107906745, 1.9732107906745, 1.9732107916391408, 1.9732107916391408, 1.9732107916391408, 1.9732107916391408, 1.9732107916391408, 1.9732107916391408, 1.97321079164598, 1.97321079164598, 4.6747681687553335, 5.82324726496606, 6.68070377104275, 7.308259276643428, 4.640715751232117, 3.239369675965217, 4.758455145553507, 3.324213569517962, 8.86993162664965, 22.46660221315835, 5.370142711685147, 3.935937426997124, 3.944696969085683, 3.986266603998276, 40.780124567760886, 15.034402983620938, 14.365266969831543, 6.023869216001719, 8.210517163220711, 6.868618338301559, 5.6277457951335155, 4.3868732520688045, 4.386873261243794, 3.1460007092673457, 3.1460007092673457, 2.52556443813613, 2.52556443813613, 2.52556443813613, 2.52556443813613, 2.52556443813613, 2.52556443813613, 2.52556443813613, 2.52556443813613, 2.52556444777918, 2.52556444777918, 2.52556444777918, 1.9051281675610419, 1.9051281675610419, 1.9051281675610419, 1.9051281675610419, 1.9051281675610419, 1.9051281675610419, 1.9051281776891862, 1.9051281776891862, 1.9051281776891862, 3.757678856133845, 3.137242183165737, 3.137242183165737, 3.180037912449524, 15.034402983620938, 13.899912160881158, 3.7489185706981853, 3.8337624134052692, 40.780124567760886, 5.3938043826988435, 22.46660221315835, 7.6510171200554735, 7.801949344659247, 2.4992862560029776, 2.4992862560029776, 2.4992862560029776, 2.4992862630120722, 2.499286272873315, 2.4992862855867246, 1.8876093797511801, 1.8876093797511801, 1.8876093797511801, 1.8876093887379901, 1.8876093887379901, 1.8876093887379901, 1.8876093887379901, 1.8876093887379901, 1.8876093887379901, 1.8876093887379901, 1.8876094042739493, 3.1958074334649034, 3.237420350714385, 1.2759325160596426, 1.2759325160596426, 1.2759325160596426, 1.2759325160596426, 1.2759325160596426, 1.2759325160596426, 1.2759325160596426, 1.2759325160596426, 1.2759325160596426, 1.2759325160596426, 1.2759325160596426, 4.585459073915555, 3.808238127682623, 2.584178722531777, 2.5841333937639748, 2.625753380066996, 2.625754789600789, 2.625754789600789, 2.625755784240352, 5.862133583808075, 15.034402983620938, 6.517521619668166, 4.7130462141291165, 4.713752813184935, 40.780124567760886, 5.208832098478375, 15.0787002740359, 5.8292383719709555, 13.731492717274051, 3.322264405747119, 5.2969889685759135, 3.238651873566128, 3.9427126114398017, 3.20461303458518, 3.204570484070522], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.5688, -4.6838, -4.9634, -4.9709, -5.1393, -5.3529, -5.3529, -5.3529, -5.3553, -5.3553, -5.6248, -5.6248, -5.6248, -5.6248, -5.6248, -5.6248, -5.6248, -5.6248, -5.6248, -5.6248, -5.6297, -4.4659, -5.9995, -5.9995, -5.9995, -5.9995, -5.9995, -5.9995, -5.9995, -5.9995, -4.685, -4.9634, -5.3529, -5.3553, -5.3529, -5.3529, -4.9634, -5.3529, -3.6965, -4.4085, -4.6936, -5.3553, -5.3529, -5.3529, -5.3529, -5.2771, -5.275, -5.277, -5.3021, -5.323, -4.7985, -4.7985, -5.188, -5.188, -4.649, -5.4599, -5.4599, -5.4599, -5.4603, -5.4603, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -5.8346, -4.6489, -5.188, -4.9744, -4.3132, -5.1881, -5.4599, -5.1963, -4.4279, -5.4599, -5.4599, -5.5159, -5.188, -5.2165, -5.4598, -4.7857, -4.2823, -5.4599, -4.9743, -5.2724, -5.2866, -5.0969, -5.4599, -5.46, -4.1732, -4.5215, -5.0605, -5.0605, -5.0605, -5.0605, -5.0605, -5.3324, -5.3324, -5.3324, -5.3324, -5.3324, -5.3324, -4.5214, -4.6709, -5.7071, -5.7071, -5.7071, -5.7071, -5.7071, -5.7071, -5.7071, -5.7071, -5.7071, -5.7071, -5.7071, -5.7071, -5.7071, -5.7071, -5.7071, -4.8468, -4.671, -4.671, -4.6709, -5.0604, -5.3324, -5.0604, -5.3324, -4.671, -4.0795, -5.0604, -5.3324, -5.3323, -5.3324, -4.3915, -4.847, -5.0604, -5.3323, -5.3324, -4.0749, -4.2931, -4.5727, -4.5727, -4.9622, -4.9622, -5.2341, -5.2341, -5.2341, -5.2341, -5.2341, -5.2341, -5.2341, -5.2341, -5.2341, -5.2341, -5.2341, -5.6088, -5.6088, -5.6088, -5.6088, -5.6088, -5.6088, -5.6088, -5.6088, -5.6088, -4.9622, -5.2341, -5.2341, -5.2341, -4.0749, -4.2929, -5.2341, -5.2341, -4.4232, -5.2339, -4.7485, -5.234, -5.2341, -5.2156, -5.2156, -5.2156, -5.2156, -5.2156, -5.2156, -5.5903, -5.5903, -5.5903, -5.5903, -5.5903, -5.5903, -5.5903, -5.5903, -5.5903, -5.5903, -5.5903, -5.2156, -5.2156, -6.1964, -6.1964, -6.1964, -6.1964, -6.1964, -6.1964, -6.1964, -6.1964, -6.1964, -6.1964, -6.1964, -4.9435, -5.2156, -5.5903, -5.5903, -5.5903, -5.5903, -5.5903, -5.5903, -4.9435, -4.2746, -4.9436, -5.2155, -5.2156, -3.8773, -5.2154, -4.73, -5.2154, -5.2157, -5.5902, -5.5902, -5.5902, -5.5902, -5.5902, -5.5903], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2023, 1.1938, 1.1687, 1.1616, 1.1494, 1.1215, 1.1215, 1.1215, 1.1192, 1.1192, 1.0779, 1.0779, 1.0779, 1.0779, 1.0779, 1.0779, 1.0779, 1.0779, 1.0779, 1.0779, 1.0732, 1.0619, 0.9994, 0.9994, 0.9994, 0.9994, 0.9994, 0.9994, 0.9994, 0.9994, 0.9412, 0.9467, 0.9653, 0.963, 0.9552, 0.9454, 0.7618, 0.8284, 0.3554, 0.2395, 0.3532, 0.8172, 0.8042, 0.6956, 0.6805, 0.4583, 0.3735, 0.3776, -0.2069, -0.1827, 1.3839, 1.3839, 1.3335, 1.3335, 1.2874, 1.2871, 1.2871, 1.2871, 1.2868, 1.2868, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.204, 1.0847, 1.1397, 1.0588, 0.8271, 1.0118, 1.0865, 0.993, 0.6673, 1.0497, 1.0497, 0.9916, 0.6976, 0.6991, 0.8883, 0.2611, -0.2305, 0.7653, 0.1538, 0.3761, 0.2908, -0.4488, 0.5733, 0.4008, 1.6115, 1.5812, 1.511, 1.511, 1.511, 1.511, 1.511, 1.4615, 1.4615, 1.4615, 1.4615, 1.4615, 1.4615, 1.4496, 1.4159, 1.3733, 1.3733, 1.3733, 1.3733, 1.3733, 1.3733, 1.3733, 1.3733, 1.3733, 1.3733, 1.3733, 1.3733, 1.3733, 1.3733, 1.3733, 1.371, 1.3272, 1.1898, 1.1001, 1.1648, 1.2523, 1.1397, 1.2264, 0.9064, 0.5685, 1.0188, 1.0575, 1.0553, 1.0448, -0.3396, 0.2027, 0.0348, 0.632, 0.3223, 1.7582, 1.7392, 1.7087, 1.7087, 1.6517, 1.6517, 1.5995, 1.5995, 1.5995, 1.5995, 1.5995, 1.5995, 1.5995, 1.5995, 1.5995, 1.5995, 1.5995, 1.5067, 1.5067, 1.5067, 1.5067, 1.5067, 1.5067, 1.5067, 1.5067, 1.5067, 1.4741, 1.3826, 1.3826, 1.3691, 0.9748, 0.8352, 1.2045, 1.1821, -0.3714, 0.8409, -0.1005, 0.4912, 0.4716, 1.6284, 1.6284, 1.6284, 1.6284, 1.6284, 1.6284, 1.5344, 1.5344, 1.5344, 1.5344, 1.5344, 1.5344, 1.5344, 1.5344, 1.5344, 1.5344, 1.5344, 1.3826, 1.3697, 1.3199, 1.3199, 1.3199, 1.3199, 1.3199, 1.3199, 1.3199, 1.3199, 1.3199, 1.3199, 1.3199, 1.2937, 1.2073, 1.2204, 1.2204, 1.2044, 1.2044, 1.2044, 1.2044, 1.048, 0.7751, 0.9419, 0.9942, 0.994, 0.1746, 0.8943, 0.3167, 0.7817, -0.0753, 0.9692, 0.5027, 0.9947, 0.7979, 1.0052, 1.0052]}, \"token.table\": {\"Topic\": [5, 4, 5, 4, 5, 5, 5, 2, 1, 4, 5, 1, 3, 5, 5, 2, 1, 2, 4, 5, 3, 1, 3, 1, 2, 4, 4, 2, 2, 1, 2, 1, 2, 3, 4, 5, 5, 1, 5, 5, 3, 1, 3, 5, 2, 5, 5, 2, 3, 5, 1, 2, 3, 1, 5, 3, 5, 1, 4, 1, 3, 4, 5, 2, 3, 3, 4, 5, 1, 5, 5, 2, 5, 4, 5, 1, 5, 4, 2, 1, 2, 4, 3, 5, 2, 5, 1, 2, 3, 4, 5, 3, 5, 1, 3, 4, 2, 2, 1, 2, 3, 1, 5, 1, 1, 4, 4, 1, 3, 4, 2, 1, 4, 4, 2, 4, 5, 1, 1, 3, 4, 2, 5, 1, 3, 5, 1, 1, 5, 5, 4, 2, 3, 4, 5, 4, 4, 1, 5, 1, 2, 4, 1, 2, 5, 1, 2, 3, 4, 5, 3, 3, 3, 2, 1, 3, 4, 4, 1, 3, 1, 1, 5, 4, 5, 5, 3, 2, 4, 5, 1, 3, 1, 3, 4, 1, 1, 2, 3, 2, 4, 5, 4, 2, 4, 1, 5, 2, 2, 3, 1, 3, 3, 1, 3, 4, 2, 1, 2, 3, 4, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 3, 3, 1, 1, 2, 3, 5, 1, 2, 2, 4, 4, 1, 3, 4, 1, 2, 3, 4, 5, 1, 5, 2, 2, 2, 3, 5, 3, 4, 5, 1, 1, 2, 4, 5, 3, 2, 2, 4, 4, 2, 3, 4, 1, 2, 3, 2, 3, 2, 1, 2, 5, 5, 1, 2, 3, 5, 4, 3, 3, 3, 1, 3, 5, 1, 2, 3, 5, 2, 3, 3, 4, 1, 2, 5, 1, 5, 2, 3, 4, 4, 3, 5, 5, 1, 1, 2, 2, 5, 1, 2, 3, 4, 5, 1, 2, 2, 3, 3, 1, 3, 3, 1, 3, 1, 1, 2, 3, 2, 1, 1, 2, 5, 5, 2, 5, 1, 2, 2, 1, 5, 3, 1, 1, 5, 1, 1, 2, 4, 5, 1, 3, 1, 3, 5, 1, 5, 1, 4, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 5, 4], \"Freq\": [0.7837405093242844, 0.6375025845093778, 0.3187512922546889, 0.9118111606593108, 0.5297706220186665, 0.7837405093242844, 0.7837405093242844, 0.9721412968063999, 0.6186828465626103, 0.2062276155208701, 0.2062276155208701, 0.9343299193672997, 0.506788227713524, 0.7837405093242844, 0.7837405093242844, 0.7262577180423637, 0.2536324856898001, 0.2536324856898001, 0.2536324856898001, 0.2536324856898001, 0.761125258102381, 0.4203044767310418, 0.6304567150965628, 0.6535078828792044, 0.1307015765758409, 0.2614031531516818, 0.7919021831965809, 0.9721412968063999, 0.8258608137381436, 0.28636951558676116, 0.5727390311735223, 0.8294424458346079, 0.43099081341461254, 0.21549540670730627, 0.21549540670730627, 0.21549540670730627, 0.5297706176583923, 0.4361613456277533, 0.65424201844163, 0.7837405093242844, 0.761125258368412, 0.3724295809956979, 0.5586443714935468, 0.18621479049784895, 0.9721412984216682, 0.7837405093242844, 0.800228463304772, 0.3087704511133162, 0.3087704511133162, 0.3087704511133162, 0.6038764806738279, 0.20129216022460933, 0.20129216022460933, 0.6947509293904361, 0.7837405093242844, 0.506788227713524, 0.7837405093242844, 0.69475093390316, 0.5248990654334577, 0.34117270980044584, 0.17058635490022292, 0.17058635490022292, 0.5117590647006688, 0.9721412968063999, 0.506788227961277, 0.19954234320234177, 0.39908468640468353, 0.33257057200390294, 0.3808427295493158, 0.3808427295493158, 0.7837405093242844, 0.9721412968063999, 0.7837405093242844, 0.6375025845093778, 0.3187512922546889, 0.3808430782537867, 0.3808430782537867, 0.5248990654334577, 0.9721412968063999, 0.6955038770932374, 0.2318346256977458, 0.7919021862202029, 0.6174040631543762, 0.3087020315771881, 0.9721412968063999, 0.5297706245408769, 0.3923479923023323, 0.17165224663227038, 0.12260874759447885, 0.09808699807558308, 0.17165224663227038, 0.2625886214233449, 0.5251772428466898, 0.3707957979372029, 0.18539789896860145, 0.3707957979372029, 0.9721412968063999, 0.9721412968063999, 0.8294424355303314, 0.8071743098106637, 0.16143486196213275, 0.38084287381307097, 0.38084287381307097, 0.9817004150355157, 0.6947509400415455, 0.5248990682239542, 0.5248990682239542, 0.9343299193672997, 0.761125258102381, 0.5248990682239542, 0.7262470462621735, 0.9820731216799282, 0.7919021862202029, 0.5248990654334577, 0.3120501568232074, 0.3120501568232074, 0.3120501568232074, 0.6947509371473582, 0.21548400152163996, 0.6464520045649199, 0.21548400152163996, 0.3129099674556415, 0.625819934911283, 0.5417579611858512, 0.18058598706195042, 0.18058598706195042, 0.6947509415596359, 0.6947509268544961, 0.5297706220186665, 0.5297706220186665, 0.8884551971632503, 0.9721412984216682, 0.31446165974471624, 0.6289233194894325, 0.5297706220186665, 0.7919021831965809, 0.7919021862202029, 0.913308795472025, 0.5297706245408769, 0.20788252183094338, 0.6236475654928301, 0.20788252183094338, 0.533652298968102, 0.355768199312068, 0.177884099656034, 0.17154899768867823, 0.17154899768867823, 0.17154899768867823, 0.17154899768867823, 0.34309799537735647, 0.9710042139471402, 0.9140305579535566, 0.506788227961277, 0.9721412968063999, 0.2508612943742868, 0.5017225887485736, 0.2508612943742868, 0.7919021862202029, 0.934329920034311, 0.9140305582065952, 0.9343299193672997, 0.3088879081702613, 0.6177758163405226, 0.5334871809785741, 0.26674359048928703, 0.800228463304772, 0.5067882277117676, 0.4602976675898994, 0.1534325558632998, 0.4602976675898994, 0.7023504984630481, 0.23411683282101603, 0.2736629783225985, 0.547325956645197, 0.13683148916129925, 0.8295395503646878, 0.35569479580662283, 0.35569479580662283, 0.17784739790331142, 0.31205430024736924, 0.31205430024736924, 0.31205430024736924, 0.5248990682239542, 0.8694713070557912, 0.7919021831965809, 0.42429038586956846, 0.42429038586956846, 0.9721412968063999, 0.29936965753053174, 0.5987393150610635, 0.21391435123642763, 0.6417430537092829, 0.506788227961277, 0.8583080114362738, 0.10728850142953422, 0.10728850142953422, 0.8258608126821155, 0.39611582376261784, 0.1320386079208726, 0.1320386079208726, 0.1320386079208726, 0.7983651916136877, 0.2661217305378959, 0.3560841076054892, 0.13353154035205847, 0.31157359415480307, 0.13353154035205847, 0.04451051345068615, 0.3008230304965057, 0.6016460609930114, 0.8002284538325654, 0.9140305582065952, 0.39791227963668957, 0.26527485309112636, 0.06631871327278159, 0.06631871327278159, 0.19895613981834478, 0.13180357174363533, 0.6590178587181766, 0.13180357174363533, 0.18878649850555537, 0.18878649850555537, 0.18878649850555537, 0.18878649850555537, 0.18878649850555537, 0.761125258368412, 0.506788227713524, 0.6947509497741979, 0.21847588326839634, 0.5097770609595914, 0.07282529442279878, 0.14565058884559756, 0.3556689513528411, 0.7113379027056822, 0.9721412984216682, 0.9118111625663314, 0.8735381272449115, 0.6133242458357278, 0.20444141527857593, 0.20444141527857593, 0.1919816152822672, 0.1919816152822672, 0.1919816152822672, 0.1919816152822672, 0.3839632305645344, 0.42435399720975636, 0.42435399720975636, 0.8694713054557125, 0.9721412968063999, 0.2540690797421894, 0.5081381594843788, 0.2540690797421894, 0.6869019668913738, 0.17172549172284346, 0.17172549172284346, 0.9184748992921566, 0.36315355174851105, 0.36315355174851105, 0.12105118391617034, 0.12105118391617034, 0.506788227713524, 0.9721412968063999, 0.9721412968063999, 0.7919021862202029, 0.7919021862202029, 0.25350489729298115, 0.5070097945859623, 0.25350489729298115, 0.22548088127207355, 0.33822132190811033, 0.4509617625441471, 0.7262470462625163, 0.761125258368412, 0.9721412968063999, 0.2436847484450145, 0.487369496890029, 0.2436847484450145, 0.8002284579031803, 0.3320125202398533, 0.16600626011992664, 0.3320125202398533, 0.16600626011992664, 0.953591647695036, 0.506788227961277, 0.761125258102381, 0.9140305580194695, 0.7862364482866873, 0.15724728965733745, 0.15724728965733745, 0.3653850226924318, 0.12179500756414392, 0.24359001512828785, 0.12179500756414392, 0.9721412968063999, 0.506788227961277, 0.506788227961277, 0.7919021862202029, 0.30099952257566254, 0.30099952257566254, 0.30099952257566254, 0.709456929283885, 0.23648564309462836, 0.6303381837836239, 0.21011272792787467, 0.953591647695036, 0.7919021862202029, 0.506788227713524, 0.800228463304772, 0.8002284610605805, 0.6947509270885868, 0.2863692313809157, 0.5727384627618314, 0.3869769271250462, 0.3869769271250462, 0.1438858013526622, 0.2877716027053244, 0.1438858013526622, 0.3597145033816555, 0.0719429006763311, 0.23874768700075255, 0.7162430610022577, 0.7262577191867982, 0.9531800338022844, 0.9140305582065952, 0.1876440730197757, 0.7505762920791028, 0.506788227961277, 0.16712044339107418, 0.8356022169553708, 0.6949087994437241, 0.3162428665427549, 0.4743642998141324, 0.15812143327137745, 0.9721412968063999, 0.9343299193672997, 0.9343299193672997, 0.5942603959649694, 0.2971301979824847, 0.5297706220186665, 0.3869701392093647, 0.3869701392093647, 0.9343299193672997, 0.9721412984216682, 0.726257717470147, 0.7095293689292385, 0.2365097896430795, 0.506788227713524, 0.6947509293904361, 0.38084287381307097, 0.38084287381307097, 0.9578966684836329, 0.8294424425822191, 0.2608403683293896, 0.5216807366587792, 0.2608403683293896, 0.9343299193672997, 0.5067882277117676, 0.7103139727705147, 0.11838566212841911, 0.11838566212841911, 0.6947509497741979, 0.5297706245408769, 0.8295395710523336, 0.5248990682239542, 0.2563461914001123, 0.2563461914001123, 0.2563461914001123, 0.12817309570005614, 0.2088370516399237, 0.4176741032798474, 0.2088370516399237, 0.06961235054664122, 0.06961235054664122, 0.28577536864939607, 0.5715507372987921, 0.5297706220186665, 0.5297706220186665, 0.5248990682239542], \"Term\": [\"12\", \"13\", \"13\", \"3dmice\", \"ability\", \"academia\", \"achieve\", \"acquired\", \"across\", \"across\", \"across\", \"activity\", \"ad\", \"admission\", \"advancing\", \"air\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"alzheimers\", \"analyses\", \"analyses\", \"analysis\", \"analysis\", \"analysis\", \"analytes\", \"ant\", \"aod\", \"applications\", \"applications\", \"applied\", \"approach\", \"approach\", \"approach\", \"approach\", \"approximate\", \"architecture\", \"architecture\", \"art\", \"assessments\", \"associated\", \"associated\", \"associated\", \"atmospheric\", \"attracted\", \"autoencoders\", \"available\", \"available\", \"available\", \"based\", \"based\", \"based\", \"baselines\", \"betterpersonalized\", \"biomarkers\", \"blood\", \"capture\", \"chained\", \"challenge\", \"challenge\", \"challenge\", \"challenge\", \"characteristics\", \"circulatory\", \"clinical\", \"clinical\", \"clinical\", \"collected\", \"collected\", \"collectively\", \"colony\", \"combine\", \"commonly\", \"commonly\", \"complexity\", \"complexity\", \"contain\", \"contribution\", \"correlation\", \"correlation\", \"countries\", \"critical\", \"critical\", \"current\", \"dacmi\", \"data\", \"data\", \"data\", \"data\", \"data\", \"dataset\", \"dataset\", \"datasets\", \"datasets\", \"datasets\", \"dealing\", \"deals\", \"decomposition\", \"deep\", \"deep\", \"demonstrate\", \"demonstrate\", \"dependencies\", \"dependency\", \"determinants\", \"development\", \"dictionaries\", \"disease\", \"earnercarer\", \"ehr\", \"ehrs\", \"equality\", \"equations\", \"evaluate\", \"evaluate\", \"evaluate\", \"evaluated\", \"factors\", \"factors\", \"factors\", \"feature\", \"feature\", \"features\", \"features\", \"features\", \"fixed\", \"framework\", \"gate\", \"gates\", \"gender\", \"geographic\", \"given\", \"given\", \"glae\", \"gp\", \"graduate\", \"graph\", \"ground\", \"health\", \"health\", \"health\", \"high\", \"high\", \"high\", \"however\", \"however\", \"however\", \"however\", \"however\", \"hrqol\", \"icu\", \"illness\", \"improve\", \"including\", \"including\", \"including\", \"indicators\", \"individuals\", \"intermacs\", \"interpolation\", \"knowledge\", \"knowledge\", \"laboratory\", \"laboratory\", \"layer\", \"leading\", \"learning\", \"learning\", \"learning\", \"long\", \"long\", \"longitudinal\", \"longitudinal\", \"longitudinal\", \"longterm\", \"lstm\", \"lstm\", \"lstm\", \"machine\", \"machine\", \"machine\", \"macrolevel\", \"maiac\", \"masked\", \"matrix\", \"matrix\", \"matter\", \"mean\", \"mean\", \"measurements\", \"measurements\", \"median\", \"method\", \"method\", \"method\", \"methodology\", \"methods\", \"methods\", \"methods\", \"methods\", \"mice\", \"mice\", \"missing\", \"missing\", \"missing\", \"missing\", \"missing\", \"missingness\", \"missingness\", \"mmf\", \"mnar\", \"model\", \"model\", \"model\", \"model\", \"model\", \"modeling\", \"modeling\", \"modeling\", \"models\", \"models\", \"models\", \"models\", \"models\", \"months\", \"mri\", \"mtsit\", \"network\", \"network\", \"network\", \"network\", \"neural\", \"neural\", \"nonlinear\", \"nurse\", \"nursing\", \"observations\", \"observations\", \"observations\", \"often\", \"often\", \"often\", \"often\", \"often\", \"one\", \"one\", \"optimization\", \"particulate\", \"patient\", \"patient\", \"patient\", \"patients\", \"patients\", \"patients\", \"patterns\", \"performance\", \"performance\", \"performance\", \"performance\", \"phenotypic\", \"pm10\", \"pm25\", \"policies\", \"policy\", \"predicting\", \"predicting\", \"predicting\", \"prediction\", \"prediction\", \"prediction\", \"predictions\", \"preimplantation\", \"preprocessing\", \"presented\", \"presented\", \"presented\", \"probabilistic\", \"problem\", \"problem\", \"problem\", \"problem\", \"professionalization\", \"profile\", \"progression\", \"progressive\", \"propose\", \"propose\", \"propose\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposes\", \"random\", \"randomimputed\", \"ratios\", \"real\", \"real\", \"real\", \"realworld\", \"realworld\", \"recurrent\", \"recurrent\", \"regimes\", \"regulated\", \"relations\", \"relationships\", \"represent\", \"representation\", \"residual\", \"residual\", \"result\", \"result\", \"results\", \"results\", \"results\", \"results\", \"results\", \"rmse\", \"rmse\", \"rsup2sup\", \"scores\", \"sensitivity\", \"septic\", \"septic\", \"severity\", \"shock\", \"shock\", \"short\", \"show\", \"show\", \"show\", \"shows\", \"signal\", \"signals\", \"significant\", \"significant\", \"simultaneously\", \"single\", \"single\", \"social\", \"spatio\", \"stage\", \"stateoftheart\", \"stateoftheart\", \"status\", \"structure\", \"synthetic\", \"synthetic\", \"ta\", \"tadualcv\", \"test\", \"test\", \"test\", \"tgsd\", \"therefore\", \"time\", \"time\", \"time\", \"transformer\", \"truth\", \"two\", \"united\", \"used\", \"used\", \"used\", \"used\", \"using\", \"using\", \"using\", \"using\", \"using\", \"values\", \"values\", \"variables\", \"weight\", \"workforce\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 5, 1, 3, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2600026305195889441095926805\", ldavis_el2600026305195889441095926805_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2600026305195889441095926805\", ldavis_el2600026305195889441095926805_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2600026305195889441095926805\", ldavis_el2600026305195889441095926805_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "\n",
    "\n",
    "# Visualizar os tópicos\n",
    "pyLDAvis.enable_notebook()\n",
    "lda_vis = pyLDAvis.lda_model.prepare(lda_model, dtm, vectorizer)\n",
    "pyLDAvis.display(lda_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pyLDAvis.save_html(lda_vis, 'lda_visualization.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
